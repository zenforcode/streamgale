
<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>StreamGale: A new AI platform</title>
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reset.css"
/>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reveal.css"
/>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/theme/league.css"
  id="theme"
/>
   <style>
    table { width: 100%; font-size: 0.7em; }
    th, td { padding: 4px; border-bottom: 1px solid #444; text-align: left; }
    .mermaid { background: #fff; padding: 1em; border-radius: 10px; }
    .slides section { word-break: break-word; font-size: 0.75em; }
    iframe { width: 100%; max-width: 640px; height: 360px; margin-top: 10px; }
    blockquote { font-style: italic; border-left: 4px solid #999; padding-left: 1em; color: #ccc; }
  </style>
</head>
<body>
  <div class="reveal">
    <div class="slides">

      <section>
        <h1>StreamGale</h1>
        <p>AI-Powered Data Streaming & Aggregation</p>
        <p>Real-Time Intelligence for Cloud & Edge AI Workflows</p>
        <p><small>Giorgio Zoppi â€“ giorgio.zoppi@yenflow.com</small></p>
      </section>
      <section>
        <h2>Who I am?</h2>
        <p>Senior Software Engineer</p>
        <p><small>Msc. In Computer Science & HDip. In Artificial Intelligence Applications</small></p>
        <p>Extensive experience in cutting-edge technology development</p>
        <p>In 2013 at Hewlett-Packard, we built HP Latex 3000 Platform </p>  
        <p><a href="https://www.youtube.com/watch?v=6NxU1o-IOUM" target="_blank">â–¶ï¸ HP Latex.</a></p>
        <p>In 2022 at GM, I was part of the ADAS Data & AI Team (Ultracruise/SuperCruise).</p>
        <p><a href="https://www.youtube.com/watch?v=YXdR-gYsv60" target="_blank">â–¶ï¸ GM SuperCruise.</a></p>
      </section>

      <section>
        <h2>Problem Statement</h2>
        <ul>
          <li>AI model training is slow and expensive</li>
          <li>Medical imaging delays due to heavy file transfers</li>
          <li>Edge AI depends too heavily on cloud connectivity</li>
          <li>High costs from redundant data storage and compute</li>
        </ul>
      </section>

      <section>
        <h2>StreamGale Overview</h2>
        <ul>
          <li>Rust-based, real-time data streaming platform</li>
          <li>Optimized for AI model training, inference, and federated learning</li>
          <li>Designed for low-latency edge deployments & cloud efficiency</li>
        </ul>
      </section>

      <section>
        <h2>Market Opportunity</h2>
        <ul>
          <li>$250B+ AI Industry</li>
          <li>$30B+ Data Streaming Market</li>
          <li>$60B+ Cloud AI Market</li>
        </ul>
      </section>

      <section>
        <h2>Technology & Architecture</h2>
        <ul>
          <li>AI-optimized data pipelines</li>
          <li>Scalable across multi-cloud and on-prem environments</li>
          <li>Federated Learning built-in for privacy and performance</li>
        </ul>
      </section>
      <section>
        <h2>What is Federated Learning? </h2>
        <ul>
          <li>ğŸ“¡ StreamGale supports privacy-preserving distributed AI training</li>
          <li>ğŸ›¡ï¸ Edge devices train locally, only gradients are shared</li>
          <li>ğŸ¯ Avoids raw data transfer for better compliance and efficiency</li>
          <li>ğŸ” Algorithms supported: FedAvg, FedProx, Scaffold</li>
        </ul>
      </section>
      <section>
        <h2>Edge Inference with StreamGale</h2>
        <ul>
          <li>âš¡ Execute ML models in real-time on edge devices</li>
          <li>ğŸ”— Reduce dependency on cloud latency and costs</li>
          <li>ğŸ“¦ Supports sensor, camera, and diagnostic workloads</li>
          <li>ğŸ”’ Improves privacy by avoiding data upload</li>
        </ul>
      </section>

      <section>
        <h2>TVM Integration</h2>
        <ul>
          <li>ğŸš€ Compile and optimize models using Apache TVM</li>
          <li>ğŸ’¡ Target-specific tuning (CPU, GPU, ARM)</li>
          <li>ğŸ”„ Auto-scheduling for peak runtime performance</li>
          <li>ğŸ§© Compatible with PyTorch, TensorFlow, ONNX</li>
        </ul>
      </section>

      <section>
        <h2>Comparative Landscape</h2>
        <table>
          <thead>
            <tr>
              <th>Feature</th>
              <th>StreamGale</th>
              <th>Flower</th>
              <th>Apache Flink</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Federated Learning</td>
              <td>âœ… Built-in for edge AI</td>
              <td>âœ… FL-centric</td>
              <td>âŒ Not supported</td>
            </tr>
            <tr>
              <td>Stream Performance</td>
              <td>âœ… Rust-based, ultra-low latency</td>
              <td>âŒ Batch-oriented</td>
              <td>âœ… Java/Scala, high-throughput</td>
            </tr>
            <tr>
              <td>Edge AI Support</td>
              <td>âœ… Native support</td>
              <td>âš ï¸ Experimental</td>
              <td>âŒ Not edge-optimized</td>
            </tr>
            <tr>
              <td>Cloud Cost Optimization</td>
              <td>âœ… Core feature</td>
              <td>âš ï¸ Manual config needed</td>
              <td>âš ï¸ Indirect via tuning</td>
            </tr>
            <tr>
              <td>AI Use Case Fit</td>
              <td>ğŸ¯ FL, stream, fleet ops, training</td>
              <td>ğŸ¯ FL only</td>
              <td>ğŸ¯ Generic stream analytics</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section>
        <h3>Use Case 1: Breast Cancer Detection at the Edge</h3>
        <p><strong>Persona: Dr. Rosa Di Micco. MD</strong> â€“ Oncology, Milan San Raffaele Hospital</p>
        <ul>
          <li>ğŸ“Œ Problem: Breast Cancer Prediction</li>
          <li>âœ… Solution: StreamGale streams DICOM data directly to AI models inside the Hospital and use RNN to breast detect cancer
            in early cases.
          </li>
        </ul>
        <p><strong>ğŸ“Š Results:</strong></p>
        <ul>
          <li>ğŸ“Œ Cancer screening and detection at early stage</li>
          <li>â³ 50â€“70% faster AI-based cancer detection</li>
          <li>ğŸ¥ Oncologists looking for AI-assisted workflows</li>
        </ul>
        <p><a href="https://www.youtube.com/watch?v=gUcz7Dxp8e8" target="_blank">â–¶ï¸ Rosa Interview.</a></p>
      </section>
      <section>
        <h2>Use Case 1: Breast Cancer Detection at the Edge</h2>
        <ul>
          <li>ğŸ¥ AI runs on-site at hospital imaging centers</li>
          <li>ğŸ” Real-time DICOM streaming to edge node</li>
          <li>âš¡ AI model (TVM-compiled) performs instant analysis</li>
          <li>ğŸ§‘â€âš•ï¸ Results returned to radiologist within seconds</li>
          <li>ğŸ”’ Patient data stays within hospital boundaries</li>
        </ul>
        <img src="https://upload.wikimedia.org/wikipedia/commons/7/70/Mammogram_with_Breast_Cancer.jpg" alt="Annotated Mammogram">
        <p style="font-size: 0.65em;">Source: Wikimedia Commons</p>
      </section>
      <section>
        <h2>Use Case 1: Breast Cancer Detection at the Edge</h2>
        <pre class="mermaid">
          %%{init: {"theme": "default"}}%%
          graph LR
            A[Imaging Device] --> B[Edge Node w/ StreamGale]
            B --> C[TVM AI Model: Breast Cancer Detection]
            C --> D[Diagnosis Result - Edge]
            D --> E[Radiologist Review System]
            style A fill:#eee,stroke:#333,stroke-width:1px
            style C fill:#f96,stroke:#444,stroke-width:1px
        </pre>
      </section>
      <section>
        <h2>Impact</h2>
        <ul>
          <li>â±ï¸ Diagnosis time reduced from hours to minutes</li>
          <li>ğŸ“‰ Reduced false positives via ensemble inference</li>
          <li>ğŸ¥ Scalable across departments and hospitals</li>
          <li>ğŸ’¡ Builds trust between AI and clinicians</li>
        </ul>
        <p><strong>StreamGale empowers frontline healthcare with real-time intelligence.</strong></p>
      </section>
      <section>
        <h2>Use Case 2: Smart Fleet Operations</h2>
        <p><strong>Persona: Raj Mehta</strong> â€“ CTO, Autonomous Logistics Startup</p>
        <ul>
          <li>ğŸ“Œ Problem: Latency and cloud costs slow real-time fleet decisions</li>
          <li>âœ… Solution: StreamGale enables on-device edge AI inference</li>
        </ul>
        <p><strong>ğŸ“Š Results:</strong></p>
        <ul>
          <li>ğŸš› 30â€“50% lower cloud bandwidth costs</li>
          <li>âš¡ 20x faster edge inference</li>
          <li>ğŸ“¡ 70% less data transmitted to cloud</li>
        </ul>
        <p><a href="https://www.youtube.com/watch?v=Rodiy87t5VE" target="_blank">â–¶ï¸ Smart Fleet & Supply Chain.</a></p>
      </section>
      <section>
        <h2>Use Case 2: Reducing Fleet AI Costs with StreamGale</h2>
        <ul>
          <li>ğŸ“‰ <strong>Less Cloud Dependency:</strong> AI runs locally on edge nodes â€” no need to stream all raw video/sensor data to the cloud</li>
          <li>ğŸš› <strong>Lower Bandwidth Costs:</strong> Only metadata (like detected objects) sent, reducing cellular/network traffic by 70%</li>
          <li>âš¡ <strong>Faster Decisions:</strong> Real-time inference enables in-vehicle decision-making, improving efficiency and safety</li>
          <li>ğŸ’» <strong>Optimized Edge Inference:</strong> TVM-compilation shrinks model size, reducing hardware resource usage</li>
          <li>ğŸ” <strong>Smarter Routing & Aggregation:</strong> StreamGale orchestrates lightweight data pipelines tailored for fleet operations</li>
        </ul>
        <p><strong>Result:</strong> Operational savings, lower cloud bills, and faster, safer AI on the road.</p>
      </section>
      <section>
        <h2>Use Case 3: AI Model Training</h2>
        <p><strong>Persona: Vipul Ved Prakash</strong> â€“ Together AI, CEO</p>
        <ul>
          <li>ğŸ“Œ Problem: High costs and delays in training large AI/LLM models</li>
          <li>âœ… Solution: StreamGale reduces redundant data transfer & I/O</li>
        </ul>
        <p><strong>ğŸ“Š Results:</strong></p>
        <ul>
          <li>ğŸ’° 40â€“60% cloud compute cost savings</li>
          <li>ğŸš€ 2â€“3x faster training times</li>
          <li>ğŸŒ Seamless scaling to multi-node (GPU/TPU)</li>
        </ul>
        <p><a href="https://www.youtube.com/watch?v=6iY1VmJkx4A" target="_blank">â–¶ï¸ Customers want cost efficiency AI.</a></p>
      </section>

      <section>
        <h2>Go-To-Market Strategy</h2>
        <ul>
          <li>Enterprise partnerships: Healthcare, Supply Chain, Cloud AI</li>
          <li>Edge AI SDK integrations</li>
          <li>Engaging open-source developer community</li>
          <li>Engage AI Research Labs around Europe to optimize models.</li>
          
        </ul>
      </section>

      <section>
        <h2>Revenue Model</h2>
        <ul>
          <li>SaaS licensing for AI workflows</li>
          <li>Cloud AI training acceleration fees</li>
          <li>On-prem enterprise deployments</li>
          <li>Consulting for vertical integrations</li>
        </ul>
      </section>
      
      <section>
        <h2>StreamGale Execution Plan</h2>
        <p>This plan outlines our 6-month phased rollout to build, validate, and deploy StreamGale nodes.</p>
        <ul>
          <li>âš™ï¸ Edge + Cloud support</li>
          <li>ğŸ§  AI inference (CNN, RNN, TVM, LLMs)</li>
          <li>ğŸ“¦ Interoperability (Akka, Docker, K8s)</li>
        </ul>
      </section>

      <section>
        <h2>Phase 1 â€“ Rust Ramp-Up</h2>
        <ul>
          <li>â± Duration: 2 weeks</li>
          <li>ğŸ‘©â€ğŸ’» Team training on Rust, Tokio, Actix, Serde, Akka::Edge</li>
          <li>ğŸ”§ Setup of basic async and network primitives</li>
        </ul>
      </section>

      <section>
        <h2>Phase 2 â€“ Business & Design Discovery</h2>
        <ul>
          <li>ğŸ” Identify early adopters and strongest use cases</li>
          <li>ğŸ“Š Design domain-specific topologies and Design Node </li>
          <li>ğŸ› ï¸ Evaluate Akka Edge and integration feasibility</li>
        </ul>
      </section>

      <section>
        <h2>Phase 3 â€“ Prototype Node</h2>
        <ul>
          <li>ğŸš€ Barebones implementation of the StreamGale node</li>
          <li>âœ… Integrate TVM for model inference</li>
          <li>ğŸ”„ Test basic topology execution and data flow</li>
        </ul>
      </section>

      <section>
        <h2>Phase 4 â€“ Controller & Topology Parsing</h2>
        <ul>
          <li>ğŸ§  Introduce "Virgil" controller for orchestration</li>
          <li>ğŸ“¦ Define and parse topologies</li>
          <li>ğŸ” Translate to executable Docker/K8s/Edge binaries</li>
        </ul>
      </section>

      <section>
        <h2>Phase 5 â€“ Docker & Cloud Execution</h2>
        <ul>
          <li>ğŸ³ Dockerize key node and controller components</li>
          <li>â˜ï¸ Deploy to cloud providers for testing (AWS/GCP)</li>
          <li>ğŸ§ª Performance and cost benchmarks</li>
        </ul>
      </section>

      <section>
        <h2>Phase 6 â€“ Interoperability & Feedback Iteration</h2>
        <ul>
          <li>ğŸ”„ Refactor to support Akka, REST, and GRPC APIs</li>
          <li>ğŸ§© Interop validation with federated learning workloads</li>
          <li>ğŸ“£ Incorporate feedback from partners</li>
        </ul>
      </section>

      <section>
        <h2>Visual Timeline</h2>
        <div class="mermaid">
          %%{init: {"theme": "default"}}%%
          timeline
            title StreamGale Rollout Roadmap
            Month 0 : Rust ramp-up, async tools setup
            Month 2 : Business discovery, design topologies, first prototype
            Month 3 : Prototype node, validate TVM inference
            Month 4 : Controller & topology execution (Virgil)
            Month 5 : Docker & cloud deployments
            Month 6 : API interop, real-world use case iteration
        </div>
      </section>
      <section>
        <h2>Join the StreamGale Mission</h2>
        <p><strong>This is a volunteering project.</strong></p>
        <ul>
          <li>ğŸŒ Be part of something meaningful: help save lives and shape the future</li>
          <li>ğŸ§  Deep learning on the job: AI, models, edge inference, distributed systems</li>
          <li>ğŸ“š Constant growth: small, impactful tasks and collaborative design sessions</li>
          <li>â±ï¸ Flexible commitment: from 1â€“10 hours/week</li>
        </ul>
      </section>
      <section>
        <h2>Why Join?</h2>
        <ul>
          <li>ğŸ† Pride in building technology that matters</li>
          <li>ğŸš€ Career boost: real-world experience that sets you apart</li>
          <li>ğŸ¤ Learn from passionate peers in open design sessions</li>
          <li>ğŸ’¼ Potential future monetization if the product gains traction</li>
        </ul>
        <p><strong>Your contribution will be remembered and respected.</strong></p>
      </section>
      <section>
        <h2>Together, We Make It Happen</h2>
        <blockquote>
          "Individually, we are one drop. Together, we are an ocean."
          <br>â€“ Ryunosuke Satoro
        </blockquote>
        <p><strong>Join the team that's shaping the future of AI at the edge.</strong></p>
      </section>
    </div>
  </div>


  <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.0.5/dist/reveal.js"></script>
  <script src="plugin/markdown/markdown.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin@11.4.1/plugin/mermaid/mermaid.js"></script>
  <script>
    Reveal.initialize({
      controls: true,
      progress: true,
      center: true,
      hash: true,
  
      // mermaid initialize config
      mermaid: {
        // flowchart: {
        //   curve: 'linear',
        // },
      },
  
      // this plugin config
      // mermaidPlugin: {
      //   beforeRender(el) {
      //     console.log(el);
      //     // if return false this element will not call mermaid render
      //   },
      //
      //   afterRender(el) {
      //     console.log(el);
      //   },
      // },
  
      plugins: [RevealMermaid],
    });
  </script>
  
</body>
</html>
